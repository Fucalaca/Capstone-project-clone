// –£–î–ê–õ–ò–¢–ï —Å—Ç–∞—Ä—ã–π CONFIG –∏ –≤–µ—Å—å —Å—Ç–∞—Ä—ã–π –∫–æ–¥
// –í–°–¢–ê–í–¨–¢–ï —ç—Ç–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥:

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó!)
const CONFIG = {
    SAMPLE_RATE: 22050,
    N_MELS: 256,          // –í–∞–∂–Ω–æ: 256, –Ω–µ 64!
    MAX_LENGTH: 200,
    EMOTIONS: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],
    EMOTION_LABELS_RU: {
        'angry': 'Angry',
        'disgust': 'Disgust',
        'fear': 'Fear',
        'happy': 'Happy',
        'neutral': 'Neutral',
        'sad': 'Sad',
        'surprise': 'Surprise'
    },
    STRESS_LEVELS: {
        'angry': 'high',
        'disgust': 'medium',
        'fear': 'high',
        'happy': 'low',
        'neutral': 'low',
        'sad': 'medium',
        'surprise': 'medium'
    },
    EMOTION_EMOJIS: {
        'angry': 'üò†',
        'disgust': 'ü§¢',
        'fear': 'üò®',
        'happy': 'üòä',
        'neutral': 'üòê',
        'sad': 'üò¢',
        'surprise': 'üò≤'
    }
};

// –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
let model = null;
let audioContext = null;
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let recordingTime = 0;
let timerInterval = null;
let currentAudioBuffer = null;
let isModelLoaded = false;
let melProcessor = null;

// –≠–ª–µ–º–µ–Ω—Ç—ã DOM - –±—É–¥–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ
let recordBtn, stopBtn, playBtn, fileUpload, statusEl, timerEl;
let waveformCanvas, audioStatus, volumeLevel, durationEl;
let stressText, stressEmoji, primaryEmotion, primaryEmotionIcon;
let confidence, emotionBars, gaugeFill, modelAccuracy;
let modelProgress, modelProgressFill;

// –°–æ–≤–µ—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–º–æ—Ü–∏–π
const WELLNESS_TIPS = {
    'angry': {
        title: 'Anger Control',
        tips: [
            'Take 5 deep breaths in and out',
            'Try mindfulness techniques for 5 minutes',
            'Take a walk in the fresh air',
            'Drink a glass of water'
        ],
        supervisor: 'It is recommended to give the employee a short break'
    },
    'disgust': {
        title: 'Overcoming Disgust',
        tips: [
            'Focus on the positive aspects of the situation',
            'Talk to a colleague about your feelings',
            'Change the environment for 10-15 minutes'
        ],
        supervisor: 'Consider changing the working conditions'
    },
    'fear': {
        title: 'Reducing anxiety',
        tips: [
            'Break down big tasks into small steps',
            'Practice grounding techniques',
            'Discuss your concerns with your supervisor'
        ],
        supervisor: 'Provide clear instructions and support'
    },
    'happy': {
        title: 'Maintaining a positive mood',
        tips: [
            'Share the positivity with your colleagues',
            'Use energy for challenging tasks',
            'Plan something pleasant after work'
        ],
        supervisor: 'Use a positive attitude to motivate your team'
    },
    'neutral': {
        title: 'Maintaining balance',
        tips: [
            'Plan your day for maximum productivity',
            'Do a short warm-up session',
            'Maintain water balance'
        ],
        supervisor: 'Stable condition is optimal for work tasks'
    },
    'sad': {
        title: 'Mood boost',
        tips: [
            'Call a loved one',
            'Listen to your favorite music',
            'Do something nice for yourself',
            'Remember your recent successes'
        ],
        supervisor: 'Show empathy and offer support'
    },
    'surprise': {
        title: 'Adaptation to the unexpected',
        tips: [
            'Take a break to reflect',
            'Make a plan of action',
            'Ask for clarification if necessary'
        ],
        supervisor: 'Provide clarity and additional information'
    }
};

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
document.addEventListener('DOMContentLoaded', async () => {
    // –°–Ω–∞—á–∞–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DOM —ç–ª–µ–º–µ–Ω—Ç—ã
    initializeDOMElements();
    
    // –ó–∞—Ç–µ–º UI
    initializeUI();
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MelSpectrogram
    try {
        melProcessor = new MelSpectrogramProcessor(
            CONFIG.SAMPLE_RATE,
            CONFIG.N_MELS,
            CONFIG.MAX_LENGTH
        );
        console.log('‚úÖ MelSpectrogramProcessor initialized');
    } catch (error) {
        console.error('‚ùå Failed to initialize MelSpectrogram:', error);
        showStatus('Audio processor error', 'error');
    }
    
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    await loadModel();
    
    // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    setupEventListeners();
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    initializeAudioVisualization();
    
    console.log('‚úÖ App initialized successfully');
});

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DOM —ç–ª–µ–º–µ–Ω—Ç–æ–≤
function initializeDOMElements() {
    console.log('Initializing DOM elements...');
    
    recordBtn = document.getElementById('recordBtn');
    stopBtn = document.getElementById('stopBtn');
    playBtn = document.getElementById('playBtn');
    fileUpload = document.getElementById('fileUpload');
    statusEl = document.getElementById('status');
    timerEl = document.getElementById('timer');
    waveformCanvas = document.getElementById('waveform');
    audioStatus = document.getElementById('audioStatus');
    volumeLevel = document.getElementById('volumeLevel');
    durationEl = document.getElementById('duration');
    stressText = document.getElementById('stressText');
    stressEmoji = document.getElementById('stressEmoji');
    primaryEmotion = document.getElementById('primaryEmotion');
    primaryEmotionIcon = document.getElementById('primaryEmotionIcon');
    confidence = document.getElementById('confidence');
    emotionBars = document.getElementById('emotionBars');
    gaugeFill = document.getElementById('gaugeFill');
    modelAccuracy = document.getElementById('modelAccuracy');
    modelProgress = document.getElementById('modelProgress');
    modelProgressFill = document.getElementById('modelProgressFill');
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã
    const elements = {
        recordBtn, stopBtn, playBtn, fileUpload, statusEl, timerEl,
        waveformCanvas, audioStatus, volumeLevel, durationEl, stressText,
        stressEmoji, primaryEmotion, primaryEmotionIcon, confidence,
        emotionBars, gaugeFill, modelAccuracy, modelProgress, modelProgressFill
    };
    
    for (const [name, element] of Object.entries(elements)) {
        if (!element) {
            console.error(`‚ùå Element not found: ${name}`);
        }
    }
    
    console.log('‚úÖ DOM elements initialized');
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è UI
function initializeUI() {
    console.log('Initializing UI...');
    
    if (!emotionBars) {
        console.error('‚ùå emotionBars element not found');
        return;
    }
    
    // –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –±–∞—Ä—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
    emotionBars.innerHTML = '';
    
    // –°–æ–∑–¥–∞–µ–º –±–∞—Ä—ã –¥–ª—è —ç–º–æ—Ü–∏–π
    CONFIG.EMOTIONS.forEach(emotion => {
        const bar = document.createElement('div');
        bar.className = 'emotion-bar';
        bar.innerHTML = `
            <span class="emotion-label">${CONFIG.EMOTION_LABELS_RU[emotion]}</span>
            <div class="bar-container">
                <div class="bar-fill" data-emotion="${emotion}" 
                     style="width: 0%; background: ${getEmotionColor(emotion)};">
                    0%
                </div>
            </div>
        `;
        emotionBars.appendChild(bar);
    });
    
    console.log('‚úÖ UI initialized');
}

// –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TensorFlow.js
async function loadModel() {
    try {
        showStatus('Loading the model...', 'info');
        
        console.log('üì¶ Loading model from ./model/model.json');
        
        model = await tf.loadLayersModel('./model/model.json', {
            onProgress: (progress) => {
                const percent = Math.round(progress * 100);
                if (modelProgress) {
                    modelProgress.textContent = `${percent}%`;
                    modelProgressFill.style.width = `${percent}%`;
                }
            }
        });
        
        isModelLoaded = true;
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏
        const inputShape = model.inputs[0].shape;
        console.log('‚úÖ Model loaded successfully!');
        console.log('üìê Model input shape:', inputShape);
        console.log('‚öôÔ∏è  Expected shape: [null, 256, 200]');
        
        if (inputShape[1] === 256 && inputShape[2] === 200) {
            console.log('‚úÖ Input shape matches!');
        } else {
            console.warn(`‚ö†Ô∏è Shape mismatch! Model expects [null, ${inputShape[1]}, ${inputShape[2]}], 
                but we have [null, ${CONFIG.N_MELS}, ${CONFIG.MAX_LENGTH}]`);
        }
        
        showStatus('Model loaded successfully', 'success');
        if (modelAccuracy) {
            modelAccuracy.textContent = '71% (CRNN)';
        }
        
    } catch (error) {
        console.error('‚ùå Model loading error:', error);
        showStatus('Model loading error', 'error');
        createDemoModel();
    }
}

// –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
function createDemoModel() {
    showStatus('Using demo mode', 'warning');
    isModelLoaded = true;
    
    if (modelAccuracy) {
        modelAccuracy.textContent = '71% (demo)';
    }
    
    // –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    model = {
        predict: async (input) => {
            console.log('ü§ñ Demo model prediction');
            
            // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –¥–µ–º–æ
            const predictions = tf.tidy(() => {
                const random = tf.randomUniform([1, 7]);
                return tf.softmax(random);
            });
            return predictions;
        }
    };
    
    console.log('‚ö†Ô∏è Using demo model');
}

// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–æ–±—ã—Ç–∏–π
function setupEventListeners() {
    if (!recordBtn || !stopBtn || !playBtn || !fileUpload) {
        console.error('‚ùå Cannot setup event listeners - elements not found');
        return;
    }
    
    recordBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);
    playBtn.addEventListener('click', playAudio);
    fileUpload.addEventListener('change', handleFileUpload);
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏
    document.addEventListener('click', initializeAudioContext, { once: true });
    
    console.log('‚úÖ Event listeners setup');
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
function initializeAudioContext() {
    if (!audioContext) {
        try {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            console.log('‚úÖ AudioContext initialized');
        } catch (error) {
            console.error('‚ùå Failed to initialize AudioContext:', error);
            showStatus('Audio not supported', 'error');
        }
    }
}

// –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏
async function startRecording() {
    try {
        await initializeAudioContext();
        
        if (!audioContext) {
            showStatus('Audio not supported', 'error');
            return;
        }
        
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                sampleRate: CONFIG.SAMPLE_RATE,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true
            } 
        });
        
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = async () => {
            try {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                await processAudioBlob(audioBlob);
            } catch (error) {
                console.error('Error processing recording:', error);
                showStatus('Error processing audio', 'error');
            } finally {
                stream.getTracks().forEach(track => track.stop());
            }
        };
        
        mediaRecorder.start(100);
        isRecording = true;
        startTimer();
        
        recordBtn.disabled = true;
        stopBtn.disabled = false;
        playBtn.disabled = true;
        
        showStatus('Recording...', 'recording');
        recordBtn.classList.add('recording');
        
        updateAudioStatus('Recording...');
        
    } catch (error) {
        console.error('Recording error:', error);
        showStatus('Microphone access denied', 'error');
    }
}

// –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        stopTimer();
        
        recordBtn.disabled = false;
        stopBtn.disabled = true;
        playBtn.disabled = false;
        
        showStatus('Recording completed', 'success');
        recordBtn.classList.remove('recording');
    }
}

// –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ
function playAudio() {
    if (currentAudioBuffer && audioContext) {
        try {
            const source = audioContext.createBufferSource();
            source.buffer = currentAudioBuffer;
            source.connect(audioContext.destination);
            source.start();
            
            showStatus('Playing...', 'info');
            
            source.onended = () => {
                showStatus('Playback complete', 'success');
            };
        } catch (error) {
            console.error('Playback error:', error);
            showStatus('Playback error', 'error');
        }
    }
}

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
async function handleFileUpload(event) {
    const file = event.target.files[0];
    if (!file) return;
    
    if (!file.type.includes('audio')) {
        showStatus('Please upload an audio file', 'error');
        return;
    }
    
    if (file.size > 10 * 1024 * 1024) {
        showStatus('File too large (max 10MB)', 'error');
        return;
    }
    
    showStatus('Processing audio...', 'info');
    await processAudioBlob(file);
}

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ Blob
async function processAudioBlob(blob) {
    try {
        if (!audioContext) {
            await initializeAudioContext();
        }
        
        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        
        // –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        visualizeAudio(audioBuffer);
        currentAudioBuffer = audioBuffer;
        
        // –ò–∑–≤–ª–µ–∫–∞–µ–º Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É –∏ –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        const melFeatures = await extractMelSpectrogramFeatures(audioBuffer);
        await predictEmotion(melFeatures);
        
        playBtn.disabled = false;
        updateAudioStatus('Audio loaded');
        
    } catch (error) {
        console.error('Error processing audio:', error);
        showStatus('Error processing audio', 'error');
    }
}

// –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
async function extractMelSpectrogramFeatures(audioBuffer) {
    try {
        showStatus('Extracting Mel-spectrogram...', 'info');
        
        if (!melProcessor) {
            throw new Error('Mel processor not initialized');
        }
        
        const audioData = audioBuffer.getChannelData(0);
        const originalSampleRate = audioBuffer.sampleRate;
        
        // –†–µ—Å–∞–º–ø–ª–∏–Ω–≥ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        let processedAudio;
        if (originalSampleRate !== CONFIG.SAMPLE_RATE) {
            processedAudio = await resampleAudio(audioData, originalSampleRate, CONFIG.SAMPLE_RATE);
            console.log(`Resampled from ${originalSampleRate}Hz to ${CONFIG.SAMPLE_RATE}Hz`);
        } else {
            processedAudio = audioData;
        }
        
        // –í—ã—á–∏—Å–ª—è–µ–º Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
        const melSpec = await melProcessor.compute(processedAudio);
        
        // –î–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        melProcessor.debugMelSpectrogram(melSpec);
        
        // –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (z-score)
        const normalized = melProcessor.normalize(melSpec, 'zscore');
        
        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä [batch, n_mels, time]
        const tensor = tf.tensor([normalized]);
        
        console.log('Mel-spectrogram tensor shape:', tensor.shape);
        
        showStatus('Features extracted', 'success');
        return tensor;
        
    } catch (error) {
        console.error('Error extracting mel spectrogram:', error);
        showStatus('Error processing audio', 'error');
        
        // Fallback
        return createFallbackMelSpectrogram();
    }
}

// –§—É–Ω–∫—Ü–∏—è —Ä–µ—Å–∞–º–ø–ª–∏–Ω–≥–∞
async function resampleAudio(audioData, originalRate, targetRate) {
    if (originalRate === targetRate) return audioData;
    
    const ratio = targetRate / originalRate;
    const newLength = Math.round(audioData.length * ratio);
    const resampled = new Float32Array(newLength);
    
    for (let i = 0; i < newLength; i++) {
        const pos = i / ratio;
        const index = Math.floor(pos);
        const frac = pos - index;
        
        if (index < audioData.length - 1) {
            resampled[i] = audioData[index] * (1 - frac) + audioData[index + 1] * frac;
        } else {
            resampled[i] = audioData[audioData.length - 1];
        }
    }
    
    return resampled;
}

// Fallback —Ñ—É–Ω–∫—Ü–∏—è
function createFallbackMelSpectrogram() {
    console.log('‚ö†Ô∏è Using fallback mel spectrogram');
    const melSpec = [];
    for (let i = 0; i < CONFIG.N_MELS; i++) {
        const frame = [];
        for (let j = 0; j < CONFIG.MAX_LENGTH; j++) {
            frame.push(Math.random() * 2 - 1);
        }
        melSpec.push(frame);
    }
    return tf.tensor([melSpec]);
}

// –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —ç–º–æ—Ü–∏–∏
async function predictEmotion(features) {
    if (!isModelLoaded || !model) {
        showStatus('Model not loaded', 'error');
        return;
    }
    
    try {
        showStatus('Analyzing emotions...', 'info');
        
        console.log('Input to model shape:', features.shape);
        
        const startTime = performance.now();
        const predictions = await model.predict(features);
        const predictionArray = await predictions.data();
        predictions.dispose();
        
        const endTime = performance.now();
        console.log(`Inference time: ${(endTime - startTime).toFixed(2)} ms`);
        
        // –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—É—é —ç–º–æ—Ü–∏—é
        let maxIndex = 0;
        let maxValue = 0;
        
        const emotionProbabilities = {};
        CONFIG.EMOTIONS.forEach((emotion, index) => {
            const probability = predictionArray[index] * 100;
            emotionProbabilities[emotion] = probability;
            
            if (probability > maxValue) {
                maxValue = probability;
                maxIndex = index;
            }
        });
        
        const primaryEmotionKey = CONFIG.EMOTIONS[maxIndex];
        updateResults(primaryEmotionKey, maxValue, emotionProbabilities);
        showStatus('Analysis complete', 'success');
        
    } catch (error) {
        console.error('Prediction error:', error);
        showStatus('Analysis error', 'error');
    }
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
function updateResults(emotion, confidenceValue, probabilities) {
    // –û—Å–Ω–æ–≤–Ω–∞—è —ç–º–æ—Ü–∏—è
    if (primaryEmotion) {
        primaryEmotion.textContent = CONFIG.EMOTION_LABELS_RU[emotion];
    }
    if (primaryEmotionIcon) {
        primaryEmotionIcon.textContent = CONFIG.EMOTION_EMOJIS[emotion];
    }
    if (confidence) {
        confidence.textContent = `Confidence: ${confidenceValue.toFixed(1)}%`;
    }
    
    // –£—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞
    const stressLevel = CONFIG.STRESS_LEVELS[emotion];
    if (stressText) {
        stressText.textContent = `Stress level: ${getStressLabel(stressLevel)}`;
    }
    if (stressEmoji) {
        stressEmoji.textContent = getStressEmoji(stressLevel);
    }
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —à–∫–∞–ª—É —Å—Ç—Ä–µ—Å—Å–∞
    updateStressGauge(stressLevel);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º –±–∞—Ä—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    updateProbabilityBars(probabilities);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    updateWellnessTips(emotion);
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —à–∫–∞–ª—ã —Å—Ç—Ä–µ—Å—Å–∞
function updateStressGauge(stressLevel) {
    if (!gaugeFill) return;
    
    let height;
    switch(stressLevel) {
        case 'low': height = '25%'; break;
        case 'medium': height = '50%'; break;
        case 'high': height = '75%'; break;
        default: height = '25%';
    }
    gaugeFill.style.height = height;
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞—Ä–æ–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
function updateProbabilityBars(probabilities) {
    CONFIG.EMOTIONS.forEach(emotion => {
        const probability = probabilities[emotion] || 0;
        const barFill = document.querySelector(`.bar-fill[data-emotion="${emotion}"]`);
        if (barFill) {
            barFill.style.width = `${probability}%`;
            barFill.textContent = `${probability.toFixed(1)}%`;
            barFill.style.background = getEmotionColor(emotion);
        }
    });
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
function updateWellnessTips(emotion) {
    const tips = WELLNESS_TIPS[emotion];
    if (!tips) return;
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–≤–µ—Ç—ã –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Å—Ç—Ä–µ—Å—Å–æ–º
    const stressTip = document.getElementById('stressTip');
    if (stressTip) {
        stressTip.innerHTML = `
            <h3><i class="fas fa-lightbulb"></i> ${tips.title}</h3>
            <p>${tips.tips.slice(0, 2).join('<br>')}</p>
        `;
    }
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    const actionList = document.getElementById('actionList');
    if (actionList) {
        actionList.innerHTML = tips.tips
            .map(tip => `<li>${tip}</li>`)
            .join('');
    }
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è
    const supervisorTip = document.querySelector('#supervisorTip p');
    if (supervisorTip) {
        supervisorTip.textContent = tips.supervisor;
    }
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –¥–ª—è —ç–º–æ—Ü–∏–∏
function getEmotionColor(emotion) {
    const colors = {
        'angry': '#FF6B6B',
        'disgust': '#4ECDC4',
        'fear': '#95E1D3',
        'happy': '#FFD166',
        'neutral': '#888888',
        'sad': '#118AB2',
        'surprise': '#9D4EDD'
    };
    return colors[emotion] || '#888888';
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞
function getStressLabel(level) {
    const labels = {
        'low': 'Low',
        'medium': 'Medium',
        'high': 'High'
    };
    return labels[level] || 'Low';
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏ –¥–ª—è —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞
function getStressEmoji(level) {
    const emojis = {
        'low': 'üòä',
        'medium': 'üòê',
        'high': 'üò®'
    };
    return emojis[level] || 'üòê';
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ
function initializeAudioVisualization() {
    if (!waveformCanvas) {
        console.error('‚ùå waveformCanvas not found');
        return;
    }
    
    const ctx = waveformCanvas.getContext('2d');
    if (!ctx) {
        console.error('‚ùå Cannot get canvas context');
        return;
    }
    
    waveformCanvas.width = waveformCanvas.offsetWidth;
    waveformCanvas.height = waveformCanvas.offsetHeight;
    
    console.log('‚úÖ Audio visualization initialized');
}

// –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ
function visualizeAudio(audioBuffer) {
    if (!waveformCanvas) return;
    
    const ctx = waveformCanvas.getContext('2d');
    const width = waveformCanvas.width;
    const height = waveformCanvas.height;
    
    // –û—á–∏—â–∞–µ–º –∫–∞–Ω–≤–∞—Å
    ctx.clearRect(0, 0, width, height);
    
    // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ
    const audioData = audioBuffer.getChannelData(0);
    const step = Math.ceil(audioData.length / width);
    
    // –†–∏—Å—É–µ–º –≤–æ–ª–Ω—É
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    
    for (let i = 0; i < width; i++) {
        let sum = 0;
        for (let j = 0; j < step; j++) {
            sum += Math.abs(audioData[(i * step) + j] || 0);
        }
        const avg = sum / step;
        const y = (avg * height) / 2;
        
        ctx.lineTo(i, height / 2 - y);
        ctx.lineTo(i, height / 2 + y);
    }
    
    // –ì—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –≤–æ–ª–Ω—ã
    const gradient = ctx.createLinearGradient(0, 0, width, 0);
    gradient.addColorStop(0, '#4361ee');
    gradient.addColorStop(1, '#7209b7');
    
    ctx.strokeStyle = gradient;
    ctx.lineWidth = 2;
    ctx.stroke();
    
    // –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–¥–∏–æ
    updateAudioInfo(audioBuffer);
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—É–¥–∏–æ
function updateAudioInfo(audioBuffer) {
    const audioData = audioBuffer.getChannelData(0);
    const sampleRate = audioBuffer.sampleRate;
    
    // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –≥—Ä–æ–º–∫–æ—Å—Ç—å
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
        sum += Math.abs(audioData[i]);
    }
    const avgVolume = (sum / audioData.length) * 100;
    
    if (volumeLevel) {
        volumeLevel.textContent = `${avgVolume.toFixed(1)}%`;
    }
    if (durationEl) {
        durationEl.textContent = (audioBuffer.duration).toFixed(1);
    }
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞—É–¥–∏–æ
function updateAudioStatus(text) {
    if (audioStatus) {
        audioStatus.textContent = text;
    }
}

// –¢–∞–π–º–µ—Ä –∑–∞–ø–∏—Å–∏
function startTimer() {
    recordingTime = 0;
    updateTimerDisplay();
    timerInterval = setInterval(() => {
        recordingTime++;
        updateTimerDisplay();
        
        // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥
        if (recordingTime >= 10) {
            stopRecording();
        }
    }, 1000);
}

function stopTimer() {
    if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
    }
}

function updateTimerDisplay() {
    if (!timerEl) return;
    
    const minutes = Math.floor(recordingTime / 60).toString().padStart(2, '0');
    const seconds = (recordingTime % 60).toString().padStart(2, '0');
    timerEl.textContent = `${minutes}:${seconds}`;
}

// –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å
function showStatus(message, type = 'info') {
    if (!statusEl) {
        console.error('Status element not found');
        return;
    }
    
    statusEl.textContent = message;
    statusEl.className = 'status';
    
    switch(type) {
        case 'success':
            statusEl.style.background = '#4CAF50';
            break;
        case 'error':
            statusEl.style.background = '#F44336';
            break;
        case 'warning':
            statusEl.style.background = '#FF9800';
            break;
        case 'recording':
            statusEl.style.background = '#F44336';
            statusEl.classList.add('recording');
            break;
        default:
            statusEl.style.background = '#2196F3';
    }
}

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
window.addEventListener('error', (error) => {
    console.error('Global error:', error);
    showStatus('Application error occurred', 'error');
});

// –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Ä–∞–∑–º–µ—Ä–∞ –æ–∫–Ω–∞
window.addEventListener('resize', () => {
    if (waveformCanvas) {
        waveformCanvas.width = waveformCanvas.offsetWidth;
        waveformCanvas.height = waveformCanvas.offsetHeight;
        if (currentAudioBuffer) {
            visualizeAudio(currentAudioBuffer);
        }
    }
});

// –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
console.log(`
=== Voice Emotion Detector ===
Using CRNN model with Mel-spectrograms
N_MELS: ${CONFIG.N_MELS}, MAX_LENGTH: ${CONFIG.MAX_LENGTH}
`);
