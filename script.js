// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

const CONFIG = {
    SAMPLE_RATE: 22050,
    N_MELS: 64,          // –£–¢–û–ß–ù–ò–¢–ï —É –∫–æ–ª–ª–µ–≥–∏!
    MAX_LENGTH: 200,     // –£–¢–û–ß–ù–ò–¢–ï —É –∫–æ–ª–ª–µ–≥–∏!
    // –£–î–ê–õ–ò–¢–ï N_MFCC: 13,
    EMOTIONS: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],
    // ... –æ—Å—Ç–∞–ª—å–Ω–æ–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    STRESS_LEVELS: {
        'angry': 'high',
        'disgust': 'medium',
        'fear': 'high',
        'happy': 'low',
        'neutral': 'low',
        'sad': 'medium',
        'surprise': 'medium'
    },
    EMOTION_EMOJIS: {
        'angry': 'üò†',
        'disgust': 'ü§¢',
        'fear': 'üò®',
        'happy': 'üòä',
        'neutral': 'üòê',
        'sad': 'üò¢',
        'surprise': 'üò≤'
    }
};

// –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
let model = null;
let audioContext = null;
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let recordingTime = 0;
let timerInterval = null;
let currentAudioBuffer = null;
let isModelLoaded = false;

// –≠–ª–µ–º–µ–Ω—Ç—ã DOM
const recordBtn = document.getElementById('recordBtn');
const stopBtn = document.getElementById('stopBtn');
const playBtn = document.getElementById('playBtn');
const fileUpload = document.getElementById('fileUpload');
const statusEl = document.getElementById('status');
const timerEl = document.getElementById('timer');
const waveformCanvas = document.getElementById('waveform');
const audioStatus = document.getElementById('audioStatus');
const volumeLevel = document.getElementById('volumeLevel');
const duration = document.getElementById('duration');
const stressText = document.getElementById('stressText');
const stressEmoji = document.getElementById('stressEmoji');
const primaryEmotion = document.getElementById('primaryEmotion');
const primaryEmotionIcon = document.getElementById('primaryEmotionIcon');
const confidence = document.getElementById('confidence');
const emotionBars = document.getElementById('emotionBars');
const gaugeFill = document.getElementById('gaugeFill');
const modelAccuracy = document.getElementById('modelAccuracy');
const modelProgress = document.getElementById('modelProgress');
const modelProgressFill = document.getElementById('modelProgressFill');

// –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ DOM
document.addEventListener('DOMContentLoaded', async () => {
    initializeUI();
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ MelSpectrogram –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏
    melProcessor = new MelSpectrogram(
        CONFIG.SAMPLE_RATE,
        CONFIG.N_MELS,
        2048,  // n_fft
        512    // hop_length
    );
    
    await loadModel();
    setupEventListeners();
    initializeAudioVisualization();
});

// –°–æ–≤–µ—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–º–æ—Ü–∏–π
const WELLNESS_TIPS = {
    'angry': {
        title: 'Anger Control',
        tips: [
            'Take 5 deep breaths in and out',
            'Try mindfulness techniques for 5 minutes',
            'Take a walk in the fresh air',
            'Drink a glass of water'
        ],
        supervisor: 'It is recommended to give the employee a short break'
    },
    'disgust': {
        title: 'Overcoming Disgust',
        tips: [
            'Focus on the positive aspects of the situation',
            'Talk to a colleague about your feelings',
            'Change the environment for 10-15 minutes'
        ],
        supervisor: 'Consider changing the working conditions'
    },
    'fear': {
        title: 'Reducing anxiety',
        tips: [
            'Break down big tasks into small steps',
            'Practice grounding techniques',
            'Discuss your concerns with your supervisor'
        ],
        supervisor: 'Provide clear instructions and support'
    },
    'happy': {
        title: 'Maintaining a positive mood',
        tips: [
            'Share the positivity with your colleagues',
            'Use energy for challenging tasks',
            'Plan something pleasant after work'
        ],
        supervisor: 'Use a positive attitude to motivate your team'
    },
    'neutral': {
        title: 'Maintaining balance',
        tips: [
            'Plan your day for maximum productivity',
            'Do a short warm-up session',
            'Maintain water balance'
        ],
        supervisor: 'Stable condition is optimal for work tasks'
    },
    'sad': {
        title: 'Mood boost',
        tips: [
            'Call a loved one',
            'Listen to your favorite music',
            'Do something nice for yourself',
            'Remember your recent successes'
        ],
        supervisor: 'Show empathy and offer support'
    },
    'surprise': {
        title: 'Adaptation to the unexpected',
        tips: [
            'Take a break to reflect',
            'Make a plan of action',
            'Ask for clarification if necessary'
        ],
        supervisor: 'Provide clarity and additional information'
    }
};

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
document.addEventListener('DOMContentLoaded', async () => {
    initializeUI();
    await loadModel();
    setupEventListeners();
    initializeAudioVisualization();
});

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è UI
function initializeUI() {
    // –°–æ–∑–¥–∞–µ–º –±–∞—Ä—ã –¥–ª—è —ç–º–æ—Ü–∏–π
    CONFIG.EMOTIONS.forEach(emotion => {
        const bar = document.createElement('div');
        bar.className = 'emotion-bar';
        bar.innerHTML = `
            <span class="emotion-label">${CONFIG.EMOTION_LABELS_RU[emotion]}</span>
            <div class="bar-container">
                <div class="bar-fill" data-emotion="${emotion}" 
                     style="width: 0%; background: ${getEmotionColor(emotion)};">
                    0%
                </div>
            </div>
        `;
        emotionBars.appendChild(bar);
    });
}

// –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TensorFlow.js
async function loadModel() {
    try {
        showStatus('Loading model...', 'info');
        
        model = await tf.loadLayersModel('./model/model.json', {
            onProgress: (progress) => {
                const percent = Math.round(progress * 100);
                modelProgress.textContent = `${percent}%`;
                modelProgressFill.style.width = `${percent}%`;
            }
        });
        
        isModelLoaded = true;
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏
        const inputShape = model.inputs[0].shape;
        console.log('Model input shape:', inputShape);
        // –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: [null, N_MELS, MAX_LENGTH]
        
        // –û–±–Ω–æ–≤–ª—è–µ–º CONFIG –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if (inputShape[1] && inputShape[1] !== CONFIG.N_MELS) {
            console.warn(`Warning: Expected ${inputShape[1]} mel bands, but CONFIG has ${CONFIG.N_MELS}`);
        }
        if (inputShape[2] && inputShape[2] !== CONFIG.MAX_LENGTH) {
            console.warn(`Warning: Expected ${inputShape[2]} time steps, but CONFIG has ${CONFIG.MAX_LENGTH}`);
        }
        
        showStatus('Model loaded', 'success');
        modelAccuracy.textContent = '71% (v1)';
        
    } catch (error) {
        console.error('Model loading error:', error);
        showStatus('Model loading error', 'error');
        createDemoModel();
    }
}


// –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
function createDemoModel() {
    showStatus('v1', 'warning');
    isModelLoaded = true;
    modelAccuracy.textContent = '71% (v1)';
    
    // –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    model = {
        predict: async (input) => {
            // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –¥–µ–º–æ
            const predictions = tf.tidy(() => {
                const random = tf.randomUniform([1, 7]);
                return tf.softmax(random);
            });
            return predictions;
        }
    };
}

// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–æ–±—ã—Ç–∏–π
function setupEventListeners() {
    recordBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);
    playBtn.addEventListener('click', playAudio);
    fileUpload.addEventListener('change', handleFileUpload);
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏
    document.addEventListener('click', initializeAudioContext, { once: true });
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
function initializeAudioContext() {
    if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
    }
}

// –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏
async function startRecording() {
    try {
        await initializeAudioContext();
        
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                sampleRate: CONFIG.SAMPLE_RATE,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true
            } 
        });
        
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            await processAudioBlob(audioBlob);
            stream.getTracks().forEach(track => track.stop());
        };
        
        mediaRecorder.start(100);
        isRecording = true;
        startTimer();
        
        recordBtn.disabled = true;
        stopBtn.disabled = false;
        playBtn.disabled = true;
        
        showStatus('Recording...', 'recording');
        recordBtn.classList.add('recording');
        
        updateAudioStatus('–ó–∞–ø–∏—Å—å...');
        
    } catch (error) {
        console.error('–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏:', error);
        showStatus('Microphone access error', 'error');
    }
}

// –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        stopTimer();
        
        recordBtn.disabled = false;
        stopBtn.disabled = true;
        playBtn.disabled = false;
        
        showStatus('Recording completed', 'success');
        recordBtn.classList.remove('recording');
    }
}

// –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ
function playAudio() {
    if (currentAudioBuffer) {
        const source = audioContext.createBufferSource();
        source.buffer = currentAudioBuffer;
        source.connect(audioContext.destination);
        source.start();
        
        showStatus('Playback...', 'info');
        
        source.onended = () => {
            showStatus('Playback is complete', 'success');
        };
    }
}

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
async function handleFileUpload(event) {
    const file = event.target.files[0];
    if (!file) return;
    
    if (!file.type.includes('audio')) {
        showStatus('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª', 'error');
        return;
    }
    
    if (file.size > 10 * 1024 * 1024) { // 10MB limit
        showStatus('–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. 10MB)', 'error');
        return;
    }
    
    showStatus('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...', 'info');
    await processAudioBlob(file);
}

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ Blob
async function processAudioBlob(blob) {
    try {
        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        
        // –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        visualizeAudio(audioBuffer);
        currentAudioBuffer = audioBuffer;
        
        // –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        const melFeatures = await extractMelSpectrogramFeatures(audioBuffer);
        await predictEmotion(melFeatures);
        
        playBtn.disabled = false;
        updateAudioStatus('–ê—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ');
        
    } catch (error) {
        console.error('–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ:', error);
        showStatus('–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ', 'error');
    }
}

// –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ MFCC –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
async function extractMelSpectrogramFeatures(audioBuffer) {
    try {
        showStatus('Extracting Mel-spectrogram...', 'info');
        
        const audioData = audioBuffer.getChannelData(0);
        const sampleRate = audioBuffer.sampleRate;
        
        // –†–µ—Å–∞–º–ø–ª–∏–Ω–≥ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–≤–∞—à–∞ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç 22050 –ì—Ü)
        let processedAudio;
        if (sampleRate !== CONFIG.SAMPLE_RATE) {
            processedAudio = await resampleAudio(audioData, sampleRate, CONFIG.SAMPLE_RATE);
        } else {
            processedAudio = audioData;
        }
        
        // –í—ã—á–∏—Å–ª—è–µ–º Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
        const melSpec = await melProcessor.compute(processedAudio);
        
        // –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
        const normalized = melProcessor.normalize(melSpec, 'zscore'); // –∏–ª–∏ 'minmax'
        
        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª—è TensorFlow.js
        // –§–æ—Ä–º–∞—Ç: [batch_size, n_mels, time]
        const tensor = tf.tensor([normalized]);
        
        console.log('Mel-spectrogram shape:', tensor.shape);
        showStatus('Features extracted', 'success');
        
        return tensor;
        
    } catch (error) {
        console.error('Error extracting Mel-spectrogram:', error);
        showStatus('Error processing audio', 'error');
        
        // Fallback: —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ
        return createRandomMelSpectrogram();
    }
}

// –§—É–Ω–∫—Ü–∏—è —Ä–µ—Å–∞–º–ø–ª–∏–Ω–≥–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
async function resampleAudio(audioData, originalRate, targetRate) {
    if (originalRate === targetRate) return audioData;
    
    const ratio = targetRate / originalRate;
    const newLength = Math.round(audioData.length * ratio);
    const resampled = new Float32Array(newLength);
    
    for (let i = 0; i < newLength; i++) {
        const pos = i / ratio;
        const index = Math.floor(pos);
        const frac = pos - index;
        
        if (index < audioData.length - 1) {
            resampled[i] = audioData[index] * (1 - frac) + audioData[index + 1] * frac;
        } else {
            resampled[i] = audioData[audioData.length - 1];
        }
    }
    
    return resampled;
}

// Fallback —Ñ—É–Ω–∫—Ü–∏—è
function createRandomMelSpectrogram() {
    const melSpec = [];
    for (let i = 0; i < CONFIG.N_MELS; i++) {
        const frame = [];
        for (let j = 0; j < CONFIG.MAX_LENGTH; j++) {
            frame.push(Math.random() * 2 - 1); // [-1, 1]
        }
        melSpec.push(frame);
    }
    return tf.tensor([melSpec]);
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
function updateResults(emotion, confidenceValue, probabilities) {
    // –û—Å–Ω–æ–≤–Ω–∞—è —ç–º–æ—Ü–∏—è
    primaryEmotion.textContent = CONFIG.EMOTION_LABELS_RU[emotion];
    primaryEmotionIcon.textContent = CONFIG.EMOTION_EMOJIS[emotion];
    confidence.textContent = `–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: ${confidenceValue.toFixed(1)}%`;
    
    // –£—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞
    const stressLevel = CONFIG.STRESS_LEVELS[emotion];
    stressText.textContent = `Stress level: ${getStressLabel(stressLevel)}`;
    stressEmoji.textContent = getStressEmoji(stressLevel);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —à–∫–∞–ª—É —Å—Ç—Ä–µ—Å—Å–∞
    updateStressGauge(stressLevel);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º –±–∞—Ä—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    updateProbabilityBars(probabilities);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    updateWellnessTips(emotion);
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —à–∫–∞–ª—ã —Å—Ç—Ä–µ—Å—Å–∞
function updateStressGauge(stressLevel) {
    let height;
    switch(stressLevel) {
        case 'low': height = '25%'; break;
        case 'medium': height = '50%'; break;
        case 'high': height = '75%'; break;
        default: height = '25%';
    }
    gaugeFill.style.height = height;
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞—Ä–æ–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
function updateProbabilityBars(probabilities) {
    CONFIG.EMOTIONS.forEach(emotion => {
        const probability = probabilities[emotion] || 0;
        const barFill = document.querySelector(`.bar-fill[data-emotion="${emotion}"]`);
        if (barFill) {
            barFill.style.width = `${probability}%`;
            barFill.textContent = `${probability.toFixed(1)}%`;
            barFill.style.background = getEmotionColor(emotion);
        }
    });
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
function updateWellnessTips(emotion) {
    const tips = WELLNESS_TIPS[emotion];
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–≤–µ—Ç—ã –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Å—Ç—Ä–µ—Å—Å–æ–º
    const stressTip = document.getElementById('stressTip');
    stressTip.innerHTML = `
        <h3><i class="fas fa-lightbulb"></i> ${tips.title}</h3>
        <p>${tips.tips.slice(0, 2).join('<br>')}</p>
    `;
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    const actionList = document.getElementById('actionList');
    actionList.innerHTML = tips.tips
        .map(tip => `<li>${tip}</li>`)
        .join('');
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è
    const supervisorTip = document.querySelector('#supervisorTip p');
    supervisorTip.textContent = tips.supervisor;
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –¥–ª—è —ç–º–æ—Ü–∏–∏
function getEmotionColor(emotion) {
    const colors = {
        'angry': '#FF6B6B',
        'disgust': '#4ECDC4',
        'fear': '#95E1D3',
        'happy': '#FFD166',
        'neutral': '#888888',
        'sad': '#118AB2',
        'surprise': '#9D4EDD'
    };
    return colors[emotion] || '#888888';
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞
function getStressLabel(level) {
    const labels = {
        'low': 'Low',
        'medium': 'Medium',
        'high': 'High'
    };
    return labels[level] || '–ù–∏–∑–∫–∏–π';
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏ –¥–ª—è —É—Ä–æ–≤–Ω—è —Å—Ç—Ä–µ—Å—Å–∞
function getStressEmoji(level) {
    const emojis = {
        'low': 'üòä',
        'medium': 'üòê',
        'high': 'üò®'
    };
    return emojis[level] || 'üòê';
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ
function initializeAudioVisualization() {
    const ctx = waveformCanvas.getContext('2d');
    waveformCanvas.width = waveformCanvas.offsetWidth;
    waveformCanvas.height = waveformCanvas.offsetHeight;
}

// –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ
function visualizeAudio(audioBuffer) {
    const ctx = waveformCanvas.getContext('2d');
    const width = waveformCanvas.width;
    const height = waveformCanvas.height;
    
    // –û—á–∏—â–∞–µ–º –∫–∞–Ω–≤–∞—Å
    ctx.clearRect(0, 0, width, height);
    
    // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ
    const audioData = audioBuffer.getChannelData(0);
    const step = Math.ceil(audioData.length / width);
    
    // –†–∏—Å—É–µ–º –≤–æ–ª–Ω—É
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    
    for (let i = 0; i < width; i++) {
        let sum = 0;
        for (let j = 0; j < step; j++) {
            sum += Math.abs(audioData[(i * step) + j] || 0);
        }
        const avg = sum / step;
        const y = (avg * height) / 2;
        
        ctx.lineTo(i, height / 2 - y);
        ctx.lineTo(i, height / 2 + y);
    }
    
    // –ì—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –≤–æ–ª–Ω—ã
    const gradient = ctx.createLinearGradient(0, 0, width, 0);
    gradient.addColorStop(0, '#4361ee');
    gradient.addColorStop(1, '#7209b7');
    
    ctx.strokeStyle = gradient;
    ctx.lineWidth = 2;
    ctx.stroke();
    
    // –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–¥–∏–æ
    updateAudioInfo(audioBuffer);
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—É–¥–∏–æ
function updateAudioInfo(audioBuffer) {
    const audioData = audioBuffer.getChannelData(0);
    const sampleRate = audioBuffer.sampleRate;
    
    // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –≥—Ä–æ–º–∫–æ—Å—Ç—å
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
        sum += Math.abs(audioData[i]);
    }
    const avgVolume = (sum / audioData.length) * 100;
    
    volumeLevel.textContent = `${avgVolume.toFixed(1)}%`;
    duration.textContent = (audioBuffer.duration).toFixed(1);
}

// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞—É–¥–∏–æ
function updateAudioStatus(text) {
    audioStatus.textContent = text;
}

// –¢–∞–π–º–µ—Ä –∑–∞–ø–∏—Å–∏
function startTimer() {
    recordingTime = 0;
    updateTimerDisplay();
    timerInterval = setInterval(() => {
        recordingTime++;
        updateTimerDisplay();
        
        // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥
        if (recordingTime >= 10) {
            stopRecording();
        }
    }, 1000);
}

function stopTimer() {
    if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
    }
}

function updateTimerDisplay() {
    const minutes = Math.floor(recordingTime / 60).toString().padStart(2, '0');
    const seconds = (recordingTime % 60).toString().padStart(2, '0');
    timerEl.textContent = `${minutes}:${seconds}`;
}

// –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å
function showStatus(message, type = 'info') {
    statusEl.textContent = message;
    statusEl.className = 'status';
    
    switch(type) {
        case 'success':
            statusEl.style.background = '#4CAF50';
            break;
        case 'error':
            statusEl.style.background = '#F44336';
            break;
        case 'warning':
            statusEl.style.background = '#FF9800';
            break;
        case 'recording':
            statusEl.style.background = '#F44336';
            statusEl.classList.add('recording');
            break;
        default:
            statusEl.style.background = '#2196F3';
    }
}

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
window.addEventListener('error', (error) => {
    console.error('–ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:', error);
    showStatus('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', 'error');
});

// –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Ä–∞–∑–º–µ—Ä–∞ –æ–∫–Ω–∞
window.addEventListener('resize', () => {
    waveformCanvas.width = waveformCanvas.offsetWidth;
    waveformCanvas.height = waveformCanvas.offsetHeight;
    if (currentAudioBuffer) {
        visualizeAudio(currentAudioBuffer);
    }
});

// –í —Ñ—É–Ω–∫—Ü–∏–∏ predictEmotion –¥–æ–±–∞–≤—å—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:
async function predictEmotion(features) {
    if (!isModelLoaded) {
        showStatus('Model not loaded', 'error');
        return;
    }
    
    try {
        showStatus('Analyzing emotions...', 'info');
        
        console.log('Input to model shape:', features.shape);
        
        const startTime = performance.now();
        const predictions = await model.predict(features);
        const predictionArray = await predictions.data();
        predictions.dispose();
        
        const endTime = performance.now();
        console.log(`Inference time: ${(endTime - startTime).toFixed(2)} ms`);
        
        // ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        
    } catch (error) {
        console.error('Prediction error:', error);
        showStatus('Analysis error', 'error');
    }
}

// –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
console.log(`
=== Voice Emotion Detector ===
–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
1. –ù–∞–∂–º–∏—Ç–µ "–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å" –¥–ª—è –∑–∞–ø–∏—Å–∏ –≥–æ–ª–æ—Å–∞ (–º–∞–∫—Å. 10 —Å–µ–∫)
2. –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª (–º–∞–∫—Å. 10MB)
3. –ú–æ–¥–µ–ª—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–º–æ—Ü–∏–∏
4. –ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é:
1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π—Ç–µ PyTorch –º–æ–¥–µ–ª—å –≤ TensorFlow.js
2. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ model.json –∏ weights.bin –≤ –ø–∞–ø–∫—É model/
3. –û–±–Ω–æ–≤–∏—Ç–µ loadModel() –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
`);